{"cells":[{"cell_type":"code","metadata":{"id":"953484A276FC41FCB8126B2628779D89","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"%cd /home/mw/project/brain-seg/","outputs":[{"output_type":"stream","name":"stdout","text":"/home/mw/project/brain-seg\n"}],"execution_count":1},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F212A27125C54A33805293DECD8FEDD0","runtime":{"status":"default","execution_status":null,"is_visible":false},"notebookId":"65e91a225ad399f93b184728"},"source":"## 训练U-Net模型"},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"E4EBBB1673A74E49833FD2860805A340","runtime":{"status":"default","execution_status":null,"is_visible":false},"notebookId":"65e91a225ad399f93b184728"},"source":"新建python 3.10环境（以conda为例）  \n\n```\nconda create -n hw4 python=3.10 -y  \nconda activate hw4  \n```\n\n安装torch，注意cuda版本适配  \n```\npip install torch==2.0.* torchvision==0.15.* --index-url https://download.pytorch.org/whl/cu117  \n```\n\n安装其他依赖库  \n```\npip install ipykernel==6.26.* matplotlib==3.8.* medpy==0.4.* scipy==1.11.* numpy==1.23.* scikit-image==0.22.* imageio==2.31.* tensorboard==2.15.* tqdm==4.* -i https://pypi.tuna.tsinghua.edu.cn/simple  \n```"},{"cell_type":"code","metadata":{"id":"69DC534B39D94E4A9FF22D8A1AFD17F7","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# !pip install ipykernel==6.26.* matplotlib==3.8.* medpy==0.4.*  numpy==1.23.* scikit-image==0.22.* imageio==2.31.* tensorboard==2.15.* tqdm==4.* -i https://pypi.doubanio.com/simple/\n# !pip install tensorflow -i https://pypi.doubanio.com/simple/","outputs":[],"execution_count":29},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2024-03-06T17:26:57.279859Z","start_time":"2024-03-06T17:26:57.022169Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"CE40B72DC7A94C719EAE2AB48D0A9C06","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"import json\nimport os\n\nfrom types import SimpleNamespace\nimport tqdm\nimport numpy as np\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nfrom dataset import BrainSegmentationDataset as Dataset\nfrom logger import Logger\nfrom loss import DiceLoss\nfrom transform import transforms\nfrom unet import UNet\nfrom utils import log_images, dsc","outputs":[],"execution_count":6},{"cell_type":"markdown","metadata":{"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"F158CE4F166A4C0294E28281CCA52358","runtime":{"status":"default","execution_status":null,"is_visible":false},"notebookId":"65e91a225ad399f93b184728"},"source":"### 输入参数  \n  \ndevice: 设备编号  \nbatch_size: 批大小  \nepochs: 训练轮数  \nlr: 学习率  \nvis_images: 可视化预测结果的数目 (在tensorboard中查看)  \nvis_freq: 两次可视化预测结果的间隔  \nweights: 训练后的模型参数路径    \nimages: 数据集路径   \nimage_size: 图像尺寸   \naug_scale: 数据增强(放缩)  \naug_angle: 数据增强(旋转)  "},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2024-03-06T17:26:57.303366Z","start_time":"2024-03-06T17:26:57.281873Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"BF25D2CFC0AA448AA74DF69600A69B34","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"args = SimpleNamespace(\n    device = 'cuda:0',\n    batch_size = 16,\n    epochs = 1,\n    lr = 0.0001,\n    workers = 0,\n    vis_images = 200,\n    vis_freq = 10,\n    weights = './weights',\n    logs = './logs',\n    images = '/home/mw/input/brain_seg1509/archive/kaggle_3m',\n    image_size = 256,\n    aug_scale = 0.05,\n    aug_angle = 15,\n)","outputs":[],"execution_count":30},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2024-03-06T17:17:56.833615Z","start_time":"2024-03-06T17:17:56.785584Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"760607405BC241AE869687D76B2833F6","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"# 读取数据\ndef worker_init(worker_id):\n    np.random.seed(42 + worker_id)\n\ndef data_loaders(args):\n    dataset_train, dataset_valid = datasets(args)\n\n    loader_train = DataLoader(\n        dataset_train,\n        batch_size=args.batch_size,\n        shuffle=True,\n        drop_last=True,\n        num_workers=args.workers,\n        worker_init_fn=worker_init,\n    )\n    loader_valid = DataLoader(\n        dataset_valid,\n        batch_size=args.batch_size,\n        drop_last=False,\n        num_workers=args.workers,\n        worker_init_fn=worker_init,\n    )\n\n    return dataset_train, dataset_valid, loader_train, loader_valid\n\n# 数据集定义\ndef datasets(args):\n    train = Dataset(\n        images_dir=args.images,\n        subset=\"train\",\n        image_size=args.image_size,\n        transform=transforms(scale=args.aug_scale, angle=args.aug_angle, flip_prob=0.5),\n    )\n    valid = Dataset(\n        images_dir=args.images,\n        subset=\"validation\",\n        image_size=args.image_size,\n        random_sampling=False,\n    )\n    return train, valid\n\n# 数据处理\ndef dsc_per_volume(validation_pred, validation_true, patient_slice_index):\n    dsc_list = []\n    num_slices = np.bincount([p[0] for p in patient_slice_index])\n    index = 0\n    for p in range(len(num_slices)):\n        y_pred = np.array(validation_pred[index : index + num_slices[p]])\n        y_true = np.array(validation_true[index : index + num_slices[p]])\n        dsc_list.append(dsc(y_pred, y_true))\n        index += num_slices[p]\n    return dsc_list\n\n\ndef log_loss_summary(logger, loss, step, prefix=\"\"):\n    logger.scalar_summary(prefix + \"loss\", np.mean(loss), step)\n\n\ndef makedirs(args):\n    os.makedirs(args.weights, exist_ok=True)\n    os.makedirs(args.logs, exist_ok=True)\n\n\ndef snapshotargs(args):\n    args_file = os.path.join(args.logs, \"args.json\")\n    with open(args_file, \"w\") as fp:\n        json.dump(vars(args), fp)","outputs":[],"execution_count":8},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2024-03-06T17:17:59.513901Z","start_time":"2024-03-06T17:17:58.841711Z"},"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"800F2DFF27CD4A459452384140974A57","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"makedirs(args)\nsnapshotargs(args)\ndevice = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n\ndataset_train, dataset_valid, loader_train, loader_valid = data_loaders(args)\nloaders = {\"train\": loader_train, \"valid\": loader_valid}\n","outputs":[{"output_type":"stream","name":"stdout","text":"reading train images...\npreprocessing train volumes...\ncropping train volumes...\npadding train volumes...\nresizing train volumes...\nnormalizing train volumes...\ndone creating train dataset\nreading validation images...\npreprocessing validation volumes...\ncropping validation volumes...\npadding validation volumes...\nresizing validation volumes...\nnormalizing validation volumes...\ndone creating validation dataset\n"}],"execution_count":9},{"cell_type":"code","metadata":{"id":"0FF95C9A9F7E4E7190310FEED40812CD","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"from torch.utils.tensorboard import SummaryWriter\nfrom tensorboard.plugins.hparams import api as hp\nimport torch.nn as nn\n\ndevice = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n# 定义超参数\nHP_LR = hp.HParam('lr', hp.RealInterval(1e-5, 1e-3))\n# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([16, 32, 64]))\nHP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\nHP_LOSS_FN = hp.HParam('loss_fn', hp.Discrete(['bce_logits', 'dice', 'focal']))\n\n\nMETRIC_ACCURACY = 'accuracy'\n\n","outputs":[],"execution_count":37},{"cell_type":"code","metadata":{"id":"FAE02678AB694D80822F37B34D65C3BD","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"\n# 实现模型训练和评估的函数\n\ndef train_eval_model(hparams, device, dataset_train, dataset_valid, loader_train, loader_valid):\n    model = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n    model.to(device)\n\n    if hparams['optimizer'] == 'adam':\n        optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n\n    else:  # 'sgd'\n        optimizer = torch.optim.SGD(model.parameters(), lr=hparams['lr'], momentum=0.9)\n\n    # # Adjust batch_size according to the hyperparameter\n    # loader_train = DataLoader(dataset_train, batch_size=int(hparams[HP_BATCH_SIZE]), shuffle=True)\n    # loader_valid = DataLoader(dataset_valid, batch_size=int(hparams[HP_BATCH_SIZE]), shuffle=False)\n\n    # Training loop\n    # For demonstration, let's use just one epoch\n    for images, masks in loader_train:\n        images, masks = images.to(device), masks.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        # loss = nn.BCEWithLogitsLoss()(outputs, masks)\n        # 在训练函数中根据选择的损失函数来配置\n        if hparams['loss_fn'] == 'bce_logits':\n            loss = nn.BCEWithLogitsLoss()\n        elif hparams['loss_fn'] == 'dice':\n            loss = DiceLoss()\n        elif hparams['loss_fn'] == 'focal':\n            loss = FocalLoss()\n        loss.backward()\n        optimizer.step()\n\n    # Evaluation loop\n    with torch.no_grad():\n        num_correct = 0\n        num_pixels = 0\n        for images, masks in loader_valid:\n            images, masks = images.to(device), masks.to(device)\n            outputs = torch.sigmoid(model(images))\n            outputs = (outputs > 0.5).float()\n            num_correct += (outputs == masks).sum()\n            num_pixels += torch.numel(outputs)\n    \n    # Calculate accuracy\n    accuracy = num_correct.item() / num_pixels\n    return accuracy\n\n","outputs":[],"execution_count":34},{"cell_type":"code","metadata":{"id":"225020FAE478411FA2B5FCAF9CA433B2","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 遍历超参数的组合，训练并评估模型，记录每次运行的结果：\nsession_num = 0 \n\nimages_dir = args.images \n# 定义训练集和验证集的转换（数据增强）\ntrain_transform = transforms(scale=0.05, angle=15, flip_prob=0.5)\nvalid_transform = None  # 对于验证集，可能不需要数据增强\n\n# 初始化训练集\ndataset_train = Dataset(\n    images_dir=images_dir,\n    subset=\"train\",\n    image_size=256,\n    transform=train_transform,\n    random_sampling=True,\n    validation_cases=10,  # 假设使用10个案例进行验证\n    seed=42\n)\n\n# 初始化验证集\ndataset_valid = Dataset(\n    images_dir=images_dir,\n    subset=\"validation\",\n    image_size=256,\n    transform=valid_transform,  # 通常，验证集不应用数据增强\n    random_sampling=False,  # 验证时不需要随机采样\n    validation_cases=10,  # 同样使用10个案例进行验证\n    seed=42\n)","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"id":"FDA5278851564C48AB1386DA4F8FA6E9","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 遍历超参数的组合，训练并评估模型，记录每次运行的结果\nfor lr in np.linspace(HP_LR.domain.min_value, HP_LR.domain.max_value, num=2):\n    for loss_fn in HP_LOSS_FN.domain.values:\n        for optimizer in HP_OPTIMIZER.domain.values:\n            hparams = {\n                HP_LR.name: lr,\n                HP_OPTIMIZER.name: optimizer,\n                HP_LOSS_FN.name: loss_fn,\n            }\n            run_name = \"run-%d\" % session_num\n            print('--- Starting trial: %s' % run_name)\n            print({h: hparams[h] for h in hparams})\n            with SummaryWriter('logs/hparam_tuning/' + run_name) as writer:\n                accuracy = train_eval_model(hparams, device, dataset_train, dataset_valid, loader_train, loader_valid)\n                writer.add_hparams(hparam_dict=hparams, metric_dict={METRIC_ACCURACY: accuracy})\n            session_num += 1","outputs":[{"output_type":"stream","name":"stdout","text":"--- Starting trial: run-11\n{'lr': 1e-05, 'optimizer': 'adam', 'loss_fn': 'bce_logits'}\n--- Starting trial: run-12\n{'lr': 1e-05, 'optimizer': 'sgd', 'loss_fn': 'bce_logits'}\n--- Starting trial: run-13\n{'lr': 1e-05, 'optimizer': 'adam', 'loss_fn': 'dice'}\n--- Starting trial: run-14\n{'lr': 1e-05, 'optimizer': 'sgd', 'loss_fn': 'dice'}\n--- Starting trial: run-15\n{'lr': 1e-05, 'optimizer': 'adam', 'loss_fn': 'focal'}\n--- Starting trial: run-16\n{'lr': 1e-05, 'optimizer': 'sgd', 'loss_fn': 'focal'}\n--- Starting trial: run-17\n{'lr': 0.001, 'optimizer': 'adam', 'loss_fn': 'bce_logits'}\n--- Starting trial: run-18\n{'lr': 0.001, 'optimizer': 'sgd', 'loss_fn': 'bce_logits'}\n--- Starting trial: run-19\n{'lr': 0.001, 'optimizer': 'adam', 'loss_fn': 'dice'}\n--- Starting trial: run-20\n{'lr': 0.001, 'optimizer': 'sgd', 'loss_fn': 'dice'}\n--- Starting trial: run-21\n{'lr': 0.001, 'optimizer': 'adam', 'loss_fn': 'focal'}\n--- Starting trial: run-22\n{'lr': 0.001, 'optimizer': 'sgd', 'loss_fn': 'focal'}\n"}],"execution_count":39},{"cell_type":"code","metadata":{"id":"AF85D80D6A294FF4ACCD33A0544623C6","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"dataset_train, dataset_valid, loader_train, loader_valid","outputs":[{"output_type":"execute_result","data":{"text/plain":"(<dataset.BrainSegmentationDataset at 0x7f41025d2d60>,\n <dataset.BrainSegmentationDataset at 0x7f4102635100>,\n <torch.utils.data.dataloader.DataLoader at 0x7f416686c640>,\n <torch.utils.data.dataloader.DataLoader at 0x7f410006f400>)"},"metadata":{},"execution_count":22}],"execution_count":22},{"cell_type":"markdown","metadata":{"id":"557720D1CABC4E88A0159B7F94CBD8AE","notebookId":"65e91a225ad399f93b184728","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":""},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6800BB36C33E46E584EA4C1A66275BD7","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\nunet.to(device)\n\ndsc_loss = DiceLoss()\nbest_validation_dsc = 0.0\n\noptimizer = optim.SGD(unet.parameters(), lr=args.lr)\n\nlogger = Logger(args.logs)\nloss_train = []\nloss_valid = []\n\nstep = 0\n","outputs":[],"execution_count":31},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"3CE6C5839D524AB2A6DC83A5E08F483A","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"for epoch in range(args.epochs):\n    for phase in [\"train\", \"valid\"]:\n        if phase == \"train\":\n            unet.train()\n        else:\n            unet.eval()\n\n        validation_pred = []\n        validation_true = []\n\n        for i, data in enumerate(tqdm.tqdm(loaders[phase])):\n            if phase == \"train\":\n                step += 1\n\n            x, y_true = data\n            x, y_true = x.to(device), y_true.to(device)\n\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == \"train\"):\n                y_pred = unet(x)\n\n                loss = dsc_loss(y_pred, y_true)\n\n                if phase == \"valid\":\n                    loss_valid.append(loss.item())\n                    y_pred_np = y_pred.detach().cpu().numpy()\n                    validation_pred.extend(\n                        [y_pred_np[s] for s in range(y_pred_np.shape[0])]\n                    )\n                    y_true_np = y_true.detach().cpu().numpy()\n                    validation_true.extend(\n                        [y_true_np[s] for s in range(y_true_np.shape[0])]\n                    )\n                    if (epoch % args.vis_freq == 0) or (epoch == args.epochs - 1):\n                        if i * args.batch_size < args.vis_images:\n                            tag = \"image/{}\".format(i)\n                            num_images = args.vis_images - i * args.batch_size\n                            logger.image_list_summary(\n                                tag,\n                                log_images(x, y_true, y_pred)[:num_images],\n                                step,\n                            )\n\n                if phase == \"train\":\n                    loss_train.append(loss.item())\n                    loss.backward()\n                    optimizer.step()\n\n            if phase == \"train\" and (step + 1) % 10 == 0:\n                log_loss_summary(logger, loss_train, step)\n                loss_train = []\n\n        if phase == \"valid\":\n            log_loss_summary(logger, loss_valid, step, prefix=\"val_\")\n            print(\"epoch {} | val_loss: {}\".format(epoch + 1, np.mean(loss_valid)))\n            mean_dsc = np.mean(\n                dsc_per_volume(\n                    validation_pred,\n                    validation_true,\n                    loader_valid.dataset.patient_slice_index,\n                )\n            )\n            logger.scalar_summary(\"val_dsc\", mean_dsc, step)\n            print(\"epoch {} | val_dsc: {}\".format(epoch+1, mean_dsc))\n            if mean_dsc > best_validation_dsc:\n                best_validation_dsc = mean_dsc\n                torch.save(unet.state_dict(), os.path.join(args.weights, \"unet.pt\"))\n            loss_valid = []\n\nprint(\"Best validation mean DSC: {:4f}\".format(best_validation_dsc))","outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 208/208 [01:59<00:00,  1.73it/s]\n100%|██████████| 21/21 [01:39<00:00,  4.72s/it]\n"},{"output_type":"stream","name":"stdout","text":"epoch 1 | val_loss: 0.9674926740782601\nepoch 1 | val_dsc: 0.05731747174627673\nBest validation mean DSC: 0.057317\n"}],"execution_count":32},{"cell_type":"code","metadata":{"jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"6BC40C2376CB4D4D9C8D54E55FC1F4C1","notebookId":"65e91a225ad399f93b184728","trusted":true},"source":"%reload_ext tensorboard","outputs":[],"execution_count":33},{"cell_type":"code","metadata":{"id":"D7C355CB5EC24975890729A054A67C00","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"%tensorboard --logdir logs","outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-7a0ca6e0822e8f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-7a0ca6e0822e8f3\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}],"execution_count":36},{"cell_type":"code","metadata":{"id":"11FE1BA50AF84382850DA5F18C9150E6","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"!kill 39618","outputs":[],"execution_count":35},{"cell_type":"code","metadata":{"id":"056E2DE78B824B90BFCFE70F4F1188EB","notebookId":"65e91a225ad399f93b184728","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}