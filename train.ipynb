{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练U-Net模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建python 3.10环境（以conda为例）\n",
    "\n",
    "```\n",
    "conda create -n hw4 python=3.10 -y\n",
    "conda activate hw4\n",
    "```\n",
    "\n",
    "安装torch，注意cuda版本适配\n",
    "```\n",
    "pip install torch==2.0.* torchvision==0.15.* --index-url https://download.pytorch.org/whl/cu117\n",
    "```\n",
    "\n",
    "安装其他依赖库\n",
    "```\n",
    "pip install ipykernel==6.26.* matplotlib==3.8.* medpy==0.4.* scipy==1.11.* numpy==1.23.* scikit-image==0.22.* imageio==2.31.* tensorboard==2.15.* tqdm==4.* -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:34:10.006443Z",
     "start_time": "2024-03-07T02:33:59.397536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 10:34:04.288417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import BrainSegmentationDataset as Dataset\n",
    "from logger import Logger\n",
    "from loss import DiceLoss\n",
    "from transform import transforms\n",
    "from unet import UNet\n",
    "from utils import log_images, dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入参数  \n",
    "  \n",
    "device: 设备编号  \n",
    "batch_size: 批大小  \n",
    "epochs: 训练轮数  \n",
    "lr: 学习率  \n",
    "vis_images: 可视化预测结果的数目 (在tensorboard中查看)  \n",
    "vis_freq: 两次可视化预测结果的间隔  \n",
    "weights: 训练后的模型参数路径    \n",
    "images: 数据集路径   \n",
    "image_size: 图像尺寸   \n",
    "aug_scale: 数据增强(放缩)  \n",
    "aug_angle: 数据增强(旋转)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:34:14.800540Z",
     "start_time": "2024-03-07T02:34:14.780054Z"
    }
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    device = 'cuda:0',\n",
    "    batch_size = 16,\n",
    "    epochs = 100,\n",
    "    lr = 0.0001,\n",
    "    workers = 0,\n",
    "    vis_images = 200,\n",
    "    vis_freq = 10,\n",
    "    weights = './weights',\n",
    "    logs = './logs',\n",
    "    images = './kaggle_3m',\n",
    "    image_size = 256,\n",
    "    aug_scale = 0.05,\n",
    "    aug_angle = 15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "namespace(device='cuda:0',\n          batch_size=16,\n          epochs=100,\n          lr=0.0001,\n          workers=0,\n          vis_images=200,\n          vis_freq=10,\n          weights='./weights',\n          logs='./logs',\n          images='./kaggle_3m',\n          image_size=256,\n          aug_scale=0.05,\n          aug_angle=15)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T14:42:38.383588Z",
     "start_time": "2024-03-07T14:42:38.356349Z"
    }
   },
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: medpy==0.4.* in /usr/local/lib/python3.11/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/site-packages (from medpy==0.4.*) (1.10.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.11/site-packages (from medpy==0.4.*) (1.26.4)\r\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.11/site-packages (from medpy==0.4.*) (2.3.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.11 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 查看 numpy version\n",
    "import numpy as np\n",
    "np.__version__\n",
    "%pip install medpy==0.4.* -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T02:34:19.835729Z",
     "start_time": "2024-03-07T02:34:16.460403Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:34:24.189032Z",
     "start_time": "2024-03-07T02:34:24.164883Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def worker_init(worker_id):\n",
    "    np.random.seed(42 + worker_id)\n",
    "\n",
    "def data_loaders(args):\n",
    "    dataset_train, dataset_valid = datasets(args)\n",
    "\n",
    "    loader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args.workers,\n",
    "        worker_init_fn=worker_init,\n",
    "    )\n",
    "    loader_valid = DataLoader(\n",
    "        dataset_valid,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=False,\n",
    "        num_workers=args.workers,\n",
    "        worker_init_fn=worker_init,\n",
    "    )\n",
    "\n",
    "    return dataset_train, dataset_valid, loader_train, loader_valid\n",
    "\n",
    "# 数据集定义\n",
    "def datasets(args):\n",
    "    train = Dataset(\n",
    "        images_dir=args.images,\n",
    "        subset=\"train\",\n",
    "        image_size=args.image_size,\n",
    "        transform=transforms(scale=args.aug_scale, angle=args.aug_angle, flip_prob=0.5),\n",
    "    )\n",
    "    valid = Dataset(\n",
    "        images_dir=args.images,\n",
    "        subset=\"validation\",\n",
    "        image_size=args.image_size,\n",
    "        random_sampling=False,\n",
    "    )\n",
    "    return train, valid\n",
    "\n",
    "# 数据处理\n",
    "def dsc_per_volume(validation_pred, validation_true, patient_slice_index):\n",
    "    dsc_list = []\n",
    "    num_slices = np.bincount([p[0] for p in patient_slice_index])\n",
    "    index = 0\n",
    "    for p in range(len(num_slices)):\n",
    "        y_pred = np.array(validation_pred[index : index + num_slices[p]])\n",
    "        y_true = np.array(validation_true[index : index + num_slices[p]])\n",
    "        dsc_list.append(dsc(y_pred, y_true))\n",
    "        index += num_slices[p]\n",
    "    return dsc_list\n",
    "\n",
    "\n",
    "def log_loss_summary(logger, loss, step, prefix=\"\"):\n",
    "    logger.scalar_summary(prefix + \"loss\", np.mean(loss), step)\n",
    "\n",
    "\n",
    "def makedirs(args):\n",
    "    os.makedirs(args.weights, exist_ok=True)\n",
    "    os.makedirs(args.logs, exist_ok=True)\n",
    "\n",
    "\n",
    "def snapshotargs(args):\n",
    "    args_file = os.path.join(args.logs, \"args.json\")\n",
    "    with open(args_file, \"w\") as fp:\n",
    "        json.dump(vars(args), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:57:41.998630Z",
     "start_time": "2024-03-07T02:34:25.382266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train images...\n",
      "preprocessing train volumes...\n",
      "cropping train volumes...\n",
      "padding train volumes...\n",
      "resizing train volumes...\n",
      "normalizing train volumes...\n",
      "done creating train dataset\n",
      "reading validation images...\n",
      "preprocessing validation volumes...\n",
      "cropping validation volumes...\n",
      "padding validation volumes...\n",
      "resizing validation volumes...\n",
      "normalizing validation volumes...\n",
      "done creating validation dataset\n"
     ]
    }
   ],
   "source": [
    "makedirs(args)\n",
    "snapshotargs(args)\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else args.device)\n",
    "\n",
    "dataset_train, dataset_valid, loader_train, loader_valid = data_loaders(args)\n",
    "loaders = {\"train\": loader_train, \"valid\": loader_valid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T03:07:16.200243Z",
     "start_time": "2024-03-07T03:07:15.955470Z"
    }
   },
   "outputs": [],
   "source": [
    "unet = UNet(in_channels=Dataset.in_channels, out_channels=Dataset.out_channels)\n",
    "unet.to(device)\n",
    "\n",
    "dsc_loss = DiceLoss()\n",
    "best_validation_dsc = 0.0\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=args.lr)\n",
    "\n",
    "logger = Logger(args.logs)\n",
    "loss_train = []\n",
    "loss_valid = []\n",
    "\n",
    "step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T10:09:36.988831Z",
     "start_time": "2024-03-07T10:09:36.973659Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    for phase in [\"train\", \"valid\"]:\n",
    "        if phase == \"train\":\n",
    "            unet.train()\n",
    "        else:\n",
    "            unet.eval()\n",
    "\n",
    "        validation_pred = []\n",
    "        validation_true = []\n",
    "\n",
    "        for i, data in enumerate(tqdm.tqdm(loaders[phase])):\n",
    "            if phase == \"train\":\n",
    "                step += 1\n",
    "\n",
    "            x, y_true = data\n",
    "            x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                y_pred = unet(x)\n",
    "\n",
    "                loss = dsc_loss(y_pred, y_true)\n",
    "\n",
    "                if phase == \"valid\":\n",
    "                    loss_valid.append(loss.item())\n",
    "                    y_pred_np = y_pred.detach().cpu().numpy()\n",
    "                    validation_pred.extend(\n",
    "                        [y_pred_np[s] for s in range(y_pred_np.shape[0])]\n",
    "                    )\n",
    "                    y_true_np = y_true.detach().cpu().numpy()\n",
    "                    validation_true.extend(\n",
    "                        [y_true_np[s] for s in range(y_true_np.shape[0])]\n",
    "                    )\n",
    "                    if (epoch % args.vis_freq == 0) or (epoch == args.epochs - 1):\n",
    "                        if i * args.batch_size < args.vis_images:\n",
    "                            tag = \"image/{}\".format(i)\n",
    "                            num_images = args.vis_images - i * args.batch_size\n",
    "                            logger.image_list_summary(\n",
    "                                tag,\n",
    "                                log_images(x, y_true, y_pred)[:num_images],\n",
    "                                step,\n",
    "                            )\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss_train.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            if phase == \"train\" and (step + 1) % 10 == 0:\n",
    "                log_loss_summary(logger, loss_train, step)\n",
    "                loss_train = []\n",
    "\n",
    "        if phase == \"valid\":\n",
    "            log_loss_summary(logger, loss_valid, step, prefix=\"val_\")\n",
    "            print(\"epoch {} | val_loss: {}\".format(epoch + 1, np.mean(loss_valid)))\n",
    "            mean_dsc = np.mean(\n",
    "                dsc_per_volume(\n",
    "                    validation_pred,\n",
    "                    validation_true,\n",
    "                    loader_valid.dataset.patient_slice_index,\n",
    "                )\n",
    "            )\n",
    "            logger.scalar_summary(\"val_dsc\", mean_dsc, step)\n",
    "            print(\"epoch {} | val_dsc: {}\".format(epoch+1, mean_dsc))\n",
    "            if mean_dsc > best_validation_dsc:\n",
    "                best_validation_dsc = mean_dsc\n",
    "                torch.save(unet.state_dict(), os.path.join(args.weights, \"unet.pt\"))\n",
    "            loss_valid = []\n",
    "\n",
    "print(\"Best validation mean DSC: {:4f}\".format(best_validation_dsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T18:28:58.441793Z",
     "start_time": "2024-03-07T15:06:04.777719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 23:06:07.195576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "\r\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\r\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\r\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\r\n",
      "\r\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\r\n",
      "TensorBoard 2.15.1 at http://localhost:6008/ (Press CTRL+C to quit)\r\n",
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./logs/hparam_tuning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T14:14:05.244004Z",
     "start_time": "2024-03-07T14:14:05.141104Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-7a0ca6e0822e8f3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-7a0ca6e0822e8f3\");\n          const url = new URL(\"/\", window.location);\n          const port = 6007;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T15:04:37.826182Z",
     "start_time": "2024-03-07T15:04:37.806167Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
